<!-- build time:Sat Aug 01 2020 14:18:39 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>爬虫 | 苗春童的博客</title><meta name="description" content="CMD 命令使用curlcurl 指定一个 URL 路径，访问，并返回网页的内容：1curl www.baidu.com参数作用示例-A设置 user-agentcurl -A &quot;chrome&quot; www.baidu.com-X设置请求的方式curl -X POST www.baidu.com-I只返回请求的头信息curl -I www.baidu.com-dPOST请求携带参数"><meta property="og:type" content="article"><meta property="og:title" content="爬虫"><meta property="og:url" content="https://shijiazhuangbaifeng.github.io/2020/08/01/%E7%88%AC%E8%99%AB/index.html"><meta property="og:site_name" content="苗春童的博客"><meta property="og:description" content="CMD 命令使用curlcurl 指定一个 URL 路径，访问，并返回网页的内容：1curl www.baidu.com参数作用示例-A设置 user-agentcurl -A &quot;chrome&quot; www.baidu.com-X设置请求的方式curl -X POST www.baidu.com-I只返回请求的头信息curl -I www.baidu.com-dPOST请求携带参数"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://shijiazhuangbaifeng.github.io/2020/08/01/%E7%88%AC%E8%99%AB/Snipaste_2020-06-22_18-21-20.png"><meta property="article:published_time" content="2020-08-01T02:53:21.000Z"><meta property="article:modified_time" content="2020-08-01T06:16:43.534Z"><meta property="article:author" content="苗春童"><meta property="article:tag" content="Python"><meta property="article:tag" content="爬虫"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://shijiazhuangbaifeng.github.io/2020/08/01/%E7%88%AC%E8%99%AB/Snipaste_2020-06-22_18-21-20.png"><link rel="canonical" href="https://shijiazhuangbaifeng.github.io/2020/08/01/%E7%88%AC%E8%99%AB/index.html"><link rel="alternate" href="/atom.xml" title="苗春童的博客" type="application/atom+xml"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><meta name="generator" content="Hexo 4.2.1"></head><body class="main-center" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/cofess" target="_blank"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">昵称</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">Web Developer &amp; Designer</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shenzhen, China</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="搜索"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">首页</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">归档</span></a></li><li class="menu-item menu-item-categories"><a href="/categories"><i class="icon icon-folder"></i> <span class="menu-title">分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">标签</span></a></li><li class="menu-item menu-item-repository"><a href="/repository"><i class="icon icon-project"></i> <span class="menu-title">项目</span></a></li><li class="menu-item menu-item-books"><a href="/books"><i class="icon icon-book-fill"></i> <span class="menu-title">书单</span></a></li><li class="menu-item menu-item-links"><a href="/links"><i class="icon icon-friendship"></i> <span class="menu-title">友链</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">关于</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/ShiJiaZhuangBaiFeng/" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">公告</h3><div class="widget-body"><div id="board"><div class="content"><p>欢迎交流与分享经验!</p></div></div></div></div><div class="widget"><h3 class="widget-title">分类</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JAVA/">JAVA</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/">图像识别</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签</h3><div class="widget-body"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA/" rel="tag">JAVA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/" rel="tag">python第三方库</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/" rel="tag">全文检索</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag">分布式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%9F%E7%90%86/" rel="tag">原理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">数据可视化</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签云</h3><div class="widget-body tagcloud"><a href="/tags/JAVA/" style="font-size:13px">JAVA</a> <a href="/tags/Python/" style="font-size:13px">Python</a> <a href="/tags/python%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/" style="font-size:14px">python第三方库</a> <a href="/tags/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/" style="font-size:13px">全文检索</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size:13px">分布式</a> <a href="/tags/%E5%8E%9F%E7%90%86/" style="font-size:13px">原理</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size:14px">数据分析</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size:13.5px">数据可视化</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size:13px">爬虫</a></div></div><div class="widget"><h3 class="widget-title">归档</h3><div class="widget-body"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a><span class="archive-list-count">6</span></li></ul></div></div><div class="widget"><h3 class="widget-title">最新文章</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/08/01/#%20%E4%BB%A3%E7%90%86%E6%B1%A0/" class="title"># 代理池</a></p><p class="item-date"><time datetime="2020-08-01T05:16:51.427Z" itemprop="datePublished">2020-08-01</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/JAVA/">JAVA</a></p><p class="item-title"><a href="/2020/08/01/JVM/" class="title">JVM</a></p><p class="item-date"><time datetime="2020-08-01T02:53:21.000Z" itemprop="datePublished">2020-08-01</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></p><p class="item-title"><a href="/2020/08/01/%E7%88%AC%E8%99%AB/" class="title">爬虫</a></p><p class="item-date"><time datetime="2020-08-01T02:53:21.000Z" itemprop="datePublished">2020-08-01</time></p></div></li><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/07/31/MySql%20%E9%AB%98%E7%BA%A7/" class="title">MySql 高级</a></p><p class="item-date"><time datetime="2020-07-31T09:23:44.969Z" itemprop="datePublished">2020-07-31</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></p><p class="item-title"><a href="/2020/07/15/Eelasticsearch/" class="title">Elasticsearch</a></p><p class="item-date"><time datetime="2020-07-15T02:53:21.000Z" itemprop="datePublished">2020-07-15</time></p></div></li></ul></div></div></div></aside><aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><nav id="toc" class="article-toc"><h3 class="toc-title">文章目录</h3><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CMD-命令使用"><span class="toc-number">1.</span> <span class="toc-text">CMD 命令使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#curl"><span class="toc-number">1.1.</span> <span class="toc-text">curl</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#wget"><span class="toc-number">1.2.</span> <span class="toc-text">wget</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python-库"><span class="toc-number">2.</span> <span class="toc-text">Python 库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib"><span class="toc-number">2.1.</span> <span class="toc-text">urllib</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#使用-urllib"><span class="toc-number">2.1.1.</span> <span class="toc-text">使用 urllib</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Basic-Auth"><span class="toc-number">2.1.2.</span> <span class="toc-text">Basic Auth</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requests"><span class="toc-number">2.2.</span> <span class="toc-text">requests</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#使用-request"><span class="toc-number">2.2.1.</span> <span class="toc-text">使用 request</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#抛出异常"><span class="toc-number">2.2.2.</span> <span class="toc-text">抛出异常</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Session"><span class="toc-number">2.2.3.</span> <span class="toc-text">Session</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bs4"><span class="toc-number">2.3.</span> <span class="toc-text">bs4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#使用-bs4"><span class="toc-number">2.3.1.</span> <span class="toc-text">使用 bs4</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BeautifulSoup-常用成员"><span class="toc-number">2.3.2.</span> <span class="toc-text">BeautifulSoup 常用成员</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lxml"><span class="toc-number">2.4.</span> <span class="toc-text">lxml</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#和-bs4-整合"><span class="toc-number">2.4.1.</span> <span class="toc-text">和 bs4 整合</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#单独使用"><span class="toc-number">2.4.2.</span> <span class="toc-text">单独使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#XPATH"><span class="toc-number">2.4.3.</span> <span class="toc-text">XPATH</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy"><span class="toc-number">3.</span> <span class="toc-text">Scrapy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#使用-Scrapy"><span class="toc-number">3.1.</span> <span class="toc-text">使用 Scrapy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scrapy-入门"><span class="toc-number">3.2.</span> <span class="toc-text">Scrapy 入门</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HtmlResponse"><span class="toc-number">3.3.</span> <span class="toc-text">HtmlResponse</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#调试爬虫"><span class="toc-number">3.4.</span> <span class="toc-text">调试爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pipelines"><span class="toc-number">3.5.</span> <span class="toc-text">pipelines</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#中间件"><span class="toc-number">3.6.</span> <span class="toc-text">中间件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#process-request"><span class="toc-number">3.6.1.</span> <span class="toc-text">process_request</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#process-response"><span class="toc-number">3.6.2.</span> <span class="toc-text">process_response</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#process-exception"><span class="toc-number">3.6.3.</span> <span class="toc-text">process_exception</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy-redis"><span class="toc-number">4.</span> <span class="toc-text">scrapy-redis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-中的key"><span class="toc-number">4.1.</span> <span class="toc-text">redis 中的key</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#selenium"><span class="toc-number">5.</span> <span class="toc-text">selenium</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#启动一个浏览器"><span class="toc-number">5.1.</span> <span class="toc-text">启动一个浏览器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#控制浏览器"><span class="toc-number">5.2.</span> <span class="toc-text">控制浏览器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#input-表单操作"><span class="toc-number">5.2.1.</span> <span class="toc-text">input 表单操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#无界面"><span class="toc-number">5.3.</span> <span class="toc-text">无界面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#等待"><span class="toc-number">5.4.</span> <span class="toc-text">等待</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#隐式等待"><span class="toc-number">5.4.1.</span> <span class="toc-text">隐式等待</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#显示等待"><span class="toc-number">5.4.2.</span> <span class="toc-text">显示等待</span></a></li></ol></li></ol></li></ol></nav></div></aside><main class="main" role="main"><div class="content"><article id="post-爬虫" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">爬虫</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/2020/08/01/%E7%88%AC%E8%99%AB/" class="article-date"><time datetime="2020-08-01T02:53:21.000Z" itemprop="datePublished">2020-08-01</time></a></span> <span class="article-category"><i class="icon icon-folder"></i> <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></span> <span class="article-tag"><i class="icon icon-tags"></i> <a class="article-tag-link" href="/tags/Python/" rel="tag">Python</a>, <a class="article-tag-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2020/08/01/%E7%88%AC%E8%99%AB/#comments" class="article-comment-link">评论</a></span></div></div><div class="article-entry marked-body" itemprop="articleBody"><h2 id="CMD-命令使用"><a href="#CMD-命令使用" class="headerlink" title="CMD 命令使用"></a>CMD 命令使用</h2><h3 id="curl"><a href="#curl" class="headerlink" title="curl"></a>curl</h3><p><code>curl</code> 指定一个 <code>URL</code> 路径，访问，并返回网页的内容：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl www.baidu.com</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">参数</th><th align="center">作用</th><th align="center">示例</th></tr></thead><tbody><tr><td align="center"><code>-A</code></td><td align="center">设置 <code>user-agent</code></td><td align="center"><code>curl -A &quot;chrome&quot; www.baidu.com</code></td></tr><tr><td align="center"><code>-X</code></td><td align="center">设置请求的方式</td><td align="center"><code>curl -X POST www.baidu.com</code></td></tr><tr><td align="center"><code>-I</code></td><td align="center">只返回请求的头信息</td><td align="center"><code>curl -I www.baidu.com</code></td></tr><tr><td align="center"><code>-d</code></td><td align="center"><code>POST</code>请求携带参数</td><td align="center"><code>curl -d &quot;username=12345&amp;password=122&quot; 127.0.0.1/post</code></td></tr><tr><td align="center"><code>-O</code></td><td align="center">下载文件并以远程的文件名保存</td><td align="center"><code>curl -O http://127.0.0.1/image/jpeg</code></td></tr><tr><td align="center"><code>-o</code></td><td align="center">自定义文件名保存</td><td align="center"><code>curl -o finename http://127.0.0.1/image/jpeg</code></td></tr><tr><td align="center"><code>-L</code></td><td align="center">可以重定向</td><td align="center"><code>curl -L -I https://www.baidu.com</code></td></tr><tr><td align="center"><code>-H</code></td><td align="center">设置请求头</td><td align="center"><code>curl -H &quot;accept:image/jpeg&quot;</code></td></tr><tr><td align="center"><code>-k</code></td><td align="center">允许发送一个不安全的SSL请求</td><td align="center"></td></tr><tr><td align="center"><code>-D</code></td><td align="center">发起一个带 <code>cookie</code>的请求</td><td align="center"></td></tr><tr><td align="center"><code>-s</code></td><td align="center">不显示其他无关信息</td><td align="center"></td></tr></tbody></table><h3 id="wget"><a href="#wget" class="headerlink" title="wget"></a>wget</h3><p>下载一个文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget www.baidu.com</span><br></pre></td></tr></table></figure><h2 id="Python-库"><a href="#Python-库" class="headerlink" title="Python 库"></a>Python 库</h2><h3 id="urllib"><a href="#urllib" class="headerlink" title="urllib"></a>urllib</h3><p><code>urllib</code> 是比较基础的爬虫库，<code>Python</code> 内置的库，<code>urllib</code> 中有三个模块，分别是：</p><ul><li><code>request</code></li><li><code>response</code></li><li><code>parse</code></li></ul><h4 id="使用-urllib"><a href="#使用-urllib" class="headerlink" title="使用 urllib"></a>使用 urllib</h4><p>导入 <code>urllib.request</code> 部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">r = urllib.request.urlopen(<span class="string">'http://192.168.159.128/get'</span>)</span><br></pre></td></tr></table></figure><p><code>urllib.request.urlopen</code> 是对原始操作的封装，他的参数有： <code>url</code> 指定所需打开的网址，这个方法返回的是 <code>HttpResponse</code> 对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从缓存中读取,并解码</span></span><br><span class="line">text = r.read().decode()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为字典</span></span><br><span class="line">data = json.loads(text)</span><br><span class="line"></span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure><p>由于从 <code>HttpResponse</code> 读取到的数据是字节，需要先对数据进行解码，如果数据是 <code>json</code> 数据还可以进行转换，<code>HttpResponse</code> 的对象还可以获得状态码</p><h4 id="Basic-Auth"><a href="#Basic-Auth" class="headerlink" title="Basic Auth"></a>Basic Auth</h4><p>在登录方式有一种登录方式为 <code>Basic Auth</code> 是由浏览器来提供登录框：</p><p><img src="Snipaste_2020-06-22_18-21-20.png" alt=""></p><p><code>urllib</code> 对此提供了解决方案：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request <span class="keyword">as</span> request</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建密码管理器</span></span><br><span class="line">realm = request.HTTPPasswordMgrWithDefaultRealm()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加账号密码</span></span><br><span class="line">realm.add_password(realm=<span class="literal">None</span>, uri=<span class="string">'http://192.168.159.128/basic-auth/zhangsan/123456'</span>, user=<span class="string">"zhangsan"</span>, passwd=<span class="string">"123456"</span>)</span><br><span class="line"></span><br><span class="line">auth_handler = request.HTTPBasicAuthHandler(password_mgr=realm)</span><br><span class="line"></span><br><span class="line">opener = request.build_opener(auth_handler)</span><br><span class="line"></span><br><span class="line">request.install_opener(opener)</span><br><span class="line"></span><br><span class="line">result = request.urlopen(url=<span class="string">'http://192.168.159.128/basic-auth/zhangsan/123456'</span>)</span><br><span class="line"></span><br><span class="line">print(result.read().decode())</span><br></pre></td></tr></table></figure><h3 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h3><p><code>requests</code> 是最常用的 <code>python</code> 常用第三方库，他比 <code>urllib</code> 更加的好用，他对 <code>urllib</code> 进行了一次封装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure><h4 id="使用-request"><a href="#使用-request" class="headerlink" title="使用 request"></a>使用 request</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># GET 请求</span></span><br><span class="line">result = requests.get(<span class="string">'http://192.168.159.128/get'</span>)</span><br><span class="line">print(result.status_code, result.headers)</span><br><span class="line">print(result.json())</span><br><span class="line"></span><br><span class="line"><span class="comment"># POST 请求</span></span><br><span class="line">result = requests.post(<span class="string">'http://192.168.159.128/post'</span>)</span><br><span class="line">print(result.content)</span><br></pre></td></tr></table></figure><p>返回的对象如果是 <code>json</code> 数据，可以使用 <code>json</code> 方法直接转换为字典。</p><h4 id="抛出异常"><a href="#抛出异常" class="headerlink" title="抛出异常"></a>抛出异常</h4><p>当状态码为：<code>400 ~ 600</code> 之间的时候，抛出异常，方便查找错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.raise_for_status()</span><br></pre></td></tr></table></figure><h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 session 对象</span></span><br><span class="line">session = requests.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># get 返回数据</span></span><br><span class="line">result = session.get(<span class="string">'http://192.168.159.128/cookies/set/username/zhangsan'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下一次请求的时候会将当前的 session 的域名相关的 cookie 带上</span></span><br><span class="line">cookies = session.get(<span class="string">'http://192.168.159.128/cookies'</span>)</span><br><span class="line"></span><br><span class="line">print(cookies.json())</span><br></pre></td></tr></table></figure><h3 id="bs4"><a href="#bs4" class="headerlink" title="bs4"></a>bs4</h3><p><code>bs4</code> 是对 <code>html</code> 结构的内容进行处理，使用面向对象的方式来操作 <code>HTML</code> 内容，安装 <code>bs4</code> ：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install bs4</span><br></pre></td></tr></table></figure><h4 id="使用-bs4"><a href="#使用-bs4" class="headerlink" title="使用 bs4"></a>使用 bs4</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">result = requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"></span><br><span class="line">html_content = BeautifulSoup(result.content.decode())</span><br><span class="line"></span><br><span class="line">print(html_content.title)</span><br></pre></td></tr></table></figure><p><code>title</code> 是一个对象，使用 <code>get_text</code> 方法就能够获得标签的内容。</p><h4 id="BeautifulSoup-常用成员"><a href="#BeautifulSoup-常用成员" class="headerlink" title="BeautifulSoup 常用成员"></a>BeautifulSoup 常用成员</h4><table><thead><tr><th>方法 / 属性</th><th>作用</th></tr></thead><tbody><tr><td><code>find_all(tag)</code></td><td>根据 <code>tag</code> 标签名称获取 ，所有子节点</td></tr><tr><td><code>children</code></td><td>获取所有的子标签</td></tr><tr><td><code>select(class_name)</code></td><td>根据查询符合条件的标签，格式和 <code>css</code> 的格式一样</td></tr><tr><td><code>attrs</code></td><td>获取当前标签的属性，格式是字典</td></tr></tbody></table><h3 id="lxml"><a href="#lxml" class="headerlink" title="lxml"></a>lxml</h3><p><code>lxml</code>是<code>python</code>的一个解析库,支持<code>HTML</code>和<code>XML</code>的解析,支持XPath解析方式,而且解析效率非常高<code>XPath</code> ：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure><h4 id="和-bs4-整合"><a href="#和-bs4-整合" class="headerlink" title="和 bs4 整合"></a>和 <code>bs4</code> 整合</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">result = requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"></span><br><span class="line">html_content = BeautifulSoup(result.content.decode(), <span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'* '</span> * <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">print(html_content.text)</span><br></pre></td></tr></table></figure><h4 id="单独使用"><a href="#单独使用" class="headerlink" title="单独使用"></a>单独使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">result = requests.get(<span class="string">'http://www.huanyue123.com/book/64/64118/'</span>).content.decode(<span class="string">'gbk'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建选择器</span></span><br><span class="line">select = etree.HTML(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 页面所有的连接</span></span><br><span class="line">links = select.xpath(<span class="string">'//li/a/@href'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    print(link)</span><br></pre></td></tr></table></figure><h4 id="XPATH"><a href="#XPATH" class="headerlink" title="XPATH"></a>XPATH</h4><p>在上面的案例中使用到了 <code>XPATH</code> ，<code>XPATH</code> 不是 <code>python</code> 的库，而是一门语言，使用 <code>XPATH</code> 能够是很方便的查询。</p><h2 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h2><p><code>Scrapy</code> 是一个为了爬取网站数据，提取结构性数据的而编写的应用程序，可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p><p>安装 <code>Scrapy</code> ：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure><h3 id="使用-Scrapy"><a href="#使用-Scrapy" class="headerlink" title="使用 Scrapy"></a>使用 Scrapy</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    <span class="comment"># 爬虫名称</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    <span class="comment"># 目标网站</span></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>,]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 业务方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 获取信息</span></span><br><span class="line">        names = response.xpath(<span class="string">'//div[@class="quote"]//small/text()'</span>)</span><br><span class="line">        contents = response.xpath(<span class="string">'//div[@class="quote"]/span[@class="text"]/text()'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name, content <span class="keyword">in</span> zip(names, contents):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'author'</span>: name.extract(),</span><br><span class="line">                <span class="string">'content'</span>: content.extract()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_link = response.xpath(<span class="string">'//nav/ul/li[@class="next"]/a/@href'</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> next_link:</span><br><span class="line">            print(next_link)</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_link, self.parse)</span><br></pre></td></tr></table></figure><p>运行这个 <code>python</code> 文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider quotes_scrapy.py</span><br></pre></td></tr></table></figure><ul><li><code>-o</code> ：将内容写入到一个文件中</li><li><code>-t</code>：指定文件格式</li></ul><h3 id="Scrapy-入门"><a href="#Scrapy-入门" class="headerlink" title="Scrapy 入门"></a>Scrapy 入门</h3><p>使用命令，创建一个 <code>Scrapy</code> 项目：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject Day01</span><br></pre></td></tr></table></figure><p>该命令会创建以下的目录结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Day01&#x2F;</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    Day01&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br><span class="line">        spiders&#x2F;</span><br><span class="line">            __init__.py</span><br></pre></td></tr></table></figure><p>输入以下命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider quotes http://quotes.toscrape.com/</span><br></pre></td></tr></table></figure><p>在 <code>Day01/Day01/spiders</code> 目录下会增加一个 <code>quotes.py</code> 文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    allowed_domains = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://http://quotes.toscrape.com//'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><ul><li><code>name</code>：爬虫的名称</li><li><code>allowed_domains</code>： 所爬网页的域名必须要一致</li><li><code>start_url</code> : 爬虫网页入口</li></ul><p>在 <code>parse</code> 方法中填写业务逻辑以后，执行：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes</span><br></pre></td></tr></table></figure><h3 id="HtmlResponse"><a href="#HtmlResponse" class="headerlink" title="HtmlResponse"></a>HtmlResponse</h3><p><code>parse</code> 的 <code>response</code> 方法参数的数据类型是：<code>HtmlResponse</code>，他的常用方法有：</p><table><thead><tr><th>属性/方法</th><th>作用</th></tr></thead><tbody><tr><td><code>xpath(query)</code></td><td><code>query</code> ，支持 <code>xpath</code> 的方式获取数据，返回 <code>selector</code> 节点列表</td></tr><tr><td><code>css(query)</code></td><td>支持通过使用 <code>css</code> 的过滤数据，返回 <code>selector</code> 节点列表</td></tr><tr><td><code>extract()</code></td><td>序列化该节点为 <code>unicode</code> 字符串，返回字符列表</td></tr><tr><td><code>extract()</code></td><td>序列化该节点为 <code>unicode</code> 字符串，返回列表的第一个元素</td></tr><tr><td><code>re(query)</code></td><td>根据传入的正则表达式对数据进行提取，返回unicode字符串list列表。</td></tr></tbody></table><p>以上方法，对于 <code>selector</code> 对象同样适用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    allowed_domains = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://http://quotes.toscrape.com//'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        ....</span><br><span class="line">        <span class="keyword">yield</span> response.fllow(url, callback)</span><br><span class="line">        ....</span><br></pre></td></tr></table></figure><p><code>response.fllow</code> 的两个参数的作用为：</p><ul><li><code>url</code> ：前往的<code>url</code></li><li><code>callback</code>：回调函数，默认是 <code>parse</code></li></ul><h3 id="调试爬虫"><a href="#调试爬虫" class="headerlink" title="调试爬虫"></a>调试爬虫</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入控制台，适用的是控制台环境</span></span><br><span class="line">scrapy shell </span><br><span class="line"><span class="comment"># 进入控制台，带一个 url 参数</span></span><br><span class="line">scrapy shell url</span><br></pre></td></tr></table></figure><p>进入控制台以后，可以使用以下函数和对象：</p><table><thead><tr><th>函数</th><th>作用</th></tr></thead><tbody><tr><td><code>fetch(url)</code></td><td>请求 <code>url</code> 或 <code>request</code> 对象，使用后会刷新 <code>request</code> 和 <code>response</code> 对象</td></tr><tr><td><code>view()</code></td><td>使用浏览器打开 <code>response</code> 的网页路径</td></tr><tr><td><code>shelp()</code></td><td>打印帮助信息</td></tr><tr><td><code>spider</code></td><td>相关 <code>Spider</code> 类的实例</td></tr><tr><td><code>sttings</code></td><td>保存所有配置信息的对象</td></tr></tbody></table><h3 id="pipelines"><a href="#pipelines" class="headerlink" title="pipelines"></a>pipelines</h3><p><code>pipelines</code> 的作用相当于是 <code>AOP</code> 切面，编写在 <code>pipelines.py</code> 文件中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Day01Pipeline</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        每产生一个 item 对象，就会执行一次方法</span></span><br><span class="line"><span class="string">        :param item:</span></span><br><span class="line"><span class="string">        :param spider:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>创建好以后，需要在 <code>settings</code> 文件中配置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'Day01.pipelines.Day01Pipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ITEM_PIPELINES</code> 的 <code>key</code> 是 <code>Day01Pipeline</code> 的全路径 ,<code>value</code> 是优先级，判断是哪一个先执行，<code>process_item</code> 是必须的并且必须返回一个 <code>item</code> 对象，如果不返回就不会执行下一个 <code>process_item</code>。</p><p>如果想要将 <code>item</code> 抛弃掉，需要抛出一个异常：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reise DropItem()</span><br></pre></td></tr></table></figure><h3 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h3><p>中间件定义在 <code>middlewares</code> 文件中，中间件的方法主要有：</p><h4 id="process-request"><a href="#process-request" class="headerlink" title="process_request"></a>process_request</h4><p>在 <code>request</code> 传往 <code>downloader</code> 的过程中和将下载结果返回给 <code>engine</code> 的过程中被调用，他的返回值如下，根据返回值的不同会有不同的行为:</p><table><thead><tr><th>返回</th><th>行为</th></tr></thead><tbody><tr><td><code>None</code></td><td>一切执行正常，继续执行下一个中间件链</td></tr><tr><td><code>Response</code></td><td>停止调用 <code>process_request</code> 和 <code>process_exception</code> 方法，也不再继续执行下一个中间件，去执行<code>process_response</code></td></tr><tr><td><code>Request</code></td><td>不在调用其他的 <code>process_request</code> 方法，由调度器从新安排下载</td></tr><tr><td><code>IgnoreRequest</code></td><td><code>process_exception</code> 会被调用，如果没有此方法，则 <code>request.errback</code>会被调用，此方法也没有，该方法将会被彻底忽略</td></tr></tbody></table><h4 id="process-response"><a href="#process-response" class="headerlink" title="process_response"></a>process_response</h4><p>将下载结果返回给 <code>engine</code> 的过程中被调用：</p><table><thead><tr><th>返回</th><th>行为</th></tr></thead><tbody><tr><td><code>Response</code></td><td>继续调用其他中间件的 <code>process_response</code> 方法</td></tr><tr><td><code>Request</code></td><td>不在调用其他的 <code>process_request</code> 方法，由调度器从新安排下载</td></tr><tr><td><code>IgnoreRequest</code></td><td><code>process_exception</code> 会被调用，如果没有此方法，则 <code>request.errback</code>会被调用，此方法也没有，该方法将会被彻底忽略</td></tr></tbody></table><h4 id="process-exception"><a href="#process-exception" class="headerlink" title="process_exception"></a>process_exception</h4><p>下载的过程中发生异常或者其他方法返回 <code>IgnoreRequest</code> 的时候会被执行：</p><table><thead><tr><th>返回</th><th>行为</th></tr></thead><tbody><tr><td><code>Response</code></td><td>调用开始中间件链的 <code>process_response</code> 的流程</td></tr><tr><td><code>Request</code></td><td>不在调用其他的 <code>process_request</code> 方法，由调度器从新安排下载</td></tr><tr><td><code>None</code></td><td><code>process_exception</code> 会被调用，如果没有此方法，则 <code>request.errback</code>会被调用，此方法也没有，该方法将会被彻底忽略</td></tr></tbody></table><h2 id="scrapy-redis"><a href="#scrapy-redis" class="headerlink" title="scrapy-redis"></a>scrapy-redis</h2><p><code>scrapy-redis</code> 是 <code>scrapy</code> 的一个插件，帮助 <code>scrapy</code> 多个进程之间的协作，<code>scrapy-redis</code> 安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy-redis</span><br></pre></td></tr></table></figure><p>安装好以后，只需要在 <code>settings.py</code> 文件中修改配置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调度器</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"><span class="comment"># 过滤器</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"><span class="comment"># Redis 的路径</span></span><br><span class="line">REDIS_URL = <span class="string">'redis://user:pass@hostname:9001'</span></span><br><span class="line"><span class="comment"># 退出时清空 redis 数据</span></span><br><span class="line">SCHEDULER_PERSIST = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h3 id="redis-中的key"><a href="#redis-中的key" class="headerlink" title="redis 中的key"></a>redis 中的key</h3><p>通过 <code>redis</code> 的客户端可以看到如下的 <code>key</code>:</p><table><thead><tr><th><code>key</code></th><th><code>value</code></th></tr></thead><tbody><tr><td><code>spiderName:dupefilter</code></td><td>这个是一个 <code>set</code> 类型的数据，存储的是所有<code>url</code>，<code>32</code>位<code>md5</code>的哈希值</td></tr><tr><td><code>quotes:requests</code></td><td>类型为<code>zset</code>，存储 <code>yield</code>的<code>request</code>对象，还没有请求过得。</td></tr><tr><td><code>spiderName:items</code></td><td>这一个需要开启<code>scrapy_redis</code> 提供的<code>pipelines</code></td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h2><p><code>Selenium</code> 是一个自动化测试框架，在制作爬虫的时候因为反爬机制，无法获取数据，这个时候我们可以使用<code>selenium</code>，它相当于一个真正的浏览器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure><p>要使用这个框架，需要下载对应的浏览器驱动，放在 <code>PATH</code> 路径下。</p><h3 id="启动一个浏览器"><a href="#启动一个浏览器" class="headerlink" title="启动一个浏览器"></a>启动一个浏览器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">firefox = webdriver.Firefox()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开京东</span></span><br><span class="line">firefox.get(url)</span><br></pre></td></tr></table></figure><p>如果想要使用其他的浏览器在 <code>webdriver</code> 创建对应的对象。</p><h3 id="控制浏览器"><a href="#控制浏览器" class="headerlink" title="控制浏览器"></a>控制浏览器</h3><p>浏览器创建的对象，提供一系列的方法用来操控浏览器：</p><table><thead><tr><th>方法</th><th>作用</th></tr></thead><tbody><tr><td><code>get(url)</code></td><td>打开一个 <code>url</code></td></tr><tr><td><code>find_element_by_{tag}</code></td><td>查找一个元素，<code>{tag</code> 的选项有 <code>id</code>、<code>clss</code>、<code>xpaht</code></td></tr><tr><td><code>find_elements_by_{tag}</code></td><td>效果同上，查询多个</td></tr><tr><td><code>save_screenshot(file_name)</code></td><td>截图，将页面的内容截图下来，保存在一个文件</td></tr></tbody></table><h4 id="input-表单操作"><a href="#input-表单操作" class="headerlink" title="input 表单操作"></a>input 表单操作</h4><p>使用浏览器对象查询出 <code>input</code> 对象的时候，可以通过以下方法来操作：</p><table><thead><tr><th>方法</th><th>作用</th></tr></thead><tbody><tr><td><code>click()</code></td><td>如果是链接和按钮可以使用此方法</td></tr><tr><td><code>send_keys(key)</code></td><td>如果是一个输入框则可以使用此方法发送数据</td></tr></tbody></table><h3 id="无界面"><a href="#无界面" class="headerlink" title="无界面"></a>无界面</h3><p>使用无界面的方式来运行 <code>selenium</code> ，效果最终都是一只的，只不过不显示而已：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.firefox.options <span class="keyword">import</span> Options</span><br><span class="line">options = Options()</span><br><span class="line">options.add_argument(<span class="string">'--headless'</span>)</span><br></pre></td></tr></table></figure><p>使用不同的浏览器只要替换 <code>webdriver</code> 下的包就可以了。</p><h3 id="等待"><a href="#等待" class="headerlink" title="等待"></a>等待</h3><h4 id="隐式等待"><a href="#隐式等待" class="headerlink" title="隐式等待"></a>隐式等待</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找某一个元素如果没有立即找到就等待10秒</span></span><br><span class="line">firefox.implicitly_wait(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h4 id="显示等待"><a href="#显示等待" class="headerlink" title="显示等待"></a>显示等待</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> ec</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"></span><br><span class="line">sort_btn = WebDriverWait(fierfox, <span class="number">10</span>).until(</span><br><span class="line">    ec.presence_of_element_located(By.XPATH),</span><br><span class="line">    <span class="string">"//button"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>查找一个按钮，最常等待 <code>10</code> 秒，直到找到这个按钮。</p></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="https://shijiazhuangbaifeng.github.io/2020/08/01/%E7%88%AC%E8%99%AB/" title="爬虫" target="_blank" rel="external">https://shijiazhuangbaifeng.github.io/2020/08/01/%E7%88%AC%E8%99%AB/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！</li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/cofess" target="_blank" class="img-burn thumb-sm visible-lg"><img src="/images/avatar.jpg" class="img-rounded w-full" alt=""></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/cofess" target="_blank"><span class="text-dark">昵称</span><small class="ml-1x">Web Developer &amp; Designer</small></a></h3><div>个人简介。</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/2020/08/01/JVM/" title="JVM"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a></li><li class="next"><a href="/2020/07/31/MySql%20%E9%AB%98%E7%BA%A7/" title="MySql 高级"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li><li class="toggle-toc"><a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button"><span>[&nbsp;</span><span>文章目录</span> <i class="text-collapsed icon icon-anchor"></i> <i class="text-in icon icon-close"></i> <span>]</span></a></li></ul><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div></div></div></nav></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/ShiJiaZhuangBaiFeng/" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"><div class="publishby">Theme by <a href="https://github.com/cofess" target="_blank">cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.</div></div></footer><script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var N={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(未命名)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=N}(window)</script><script src="/js/insight.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail,link";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"",appKey:"",placeholder:"Just go go",avatar:"mm",meta:meta,pageSize:"10",visitor:!1})</script></body></html><!-- rebuild by neat -->